## code1 은 코랩에서 실행한 코드입니다.
- 쉽게 말해서 뉴스 기사 데이터를 전처리하고, 기사들의 군집을 찾아내기 위한 작업을 수행합니다.
- 구체적인 과정은 다음과 같습니다:
  
1. 필요한 라이브러리와 모듈을 임포트합니다. 
2. sentence-transformers는 문장 임베딩을 위한 라이브러리이며, datasets는 다양한 데이터셋을 다루기 위한 라이브러리입니다.
3. 시드값을 설정하여 연산 결과의 재현성을 보장합니다.
4. Google Colab 환경에서 Google Drive를 마운트합니다. 
5. 이를 통해 Google Drive에 저장된 파일을 직접 불러올 수 있습니다.
6. news.csv라는 뉴스 기사 데이터를 불러와 데이터프레임 df로 저장합니다.
7. 기사의 제목과 내용을 합쳐 text라는 새로운 열을 생성합니다.
8 .preprocess_text 함수를 정의합니다. 이 함수는 주어진 텍스트 데이터에 대한 전처리 작업을 수행합니다. 전처리 작업은 URL, 해시태그, 멘션, 이모지, 특수문자, 숫자 제거 등이 포함됩니다.
9 .preprocess_text 함수를 이용하여 text 열의 텍스트를 전처리하고 그 결과를 processed_text 열에 저장합니다.
10. Sentence BERT 모델을 로드하고, 이 모델을 사용하여 text 열의 텍스트 데이터를 임베딩합니다. 이 임베딩 결과는 sentence_embeddings에 저장됩니다.
11. sentence_embeddings를 기반으로 KMeans 알고리즘을 사용하여 군집화를 수행합니다. 군집의 개수는 6개로 설정되어 있습니다.
12. 각 군집에서 속하는 기사의 제목과 내용을 출력합니다.
13. 군집 번호를 재매핑하는 mapping_dict 딕셔너리를 정의하고, 이를 사용하여 군집 번호를 재매핑합니다.
14. sample_submission.csv라는 제출 예시 파일을 불러오고, 해당 파일의 category 열에 재매핑된 군집 번호를 저장합니다.
15. 결과를 baseline_submit.csv 파일로 저장합니다.
- 사실상 제가 한건 코랩에서 실행하는데 저장경로를 설정하고 sentence 라이브러리를 임포트하고 베이스코드를 돌린정도네요
- 코드만 돌려도 거의 4~5시간 정도 걸리니 좀 빡센 대회군요 
